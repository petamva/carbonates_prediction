{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # this is to silence tf warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.signal import savgol_filter\n",
    "# from tensorflow.keras.constraints import non_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these lines if you use a tf-gpu \n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=0)\n",
    "TRAIN_SPLIT_FRACTION = 0.9\n",
    "VAL_SPLIT_FRACTION = 0.7\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-04\n",
    "EPOCHS = 2_000\n",
    "LAMBDA = 1e-02\n",
    "PATH_SAVE = '<model save path>'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPD(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rpd\", **kwargs):\n",
    "\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.std = self.add_weight(\n",
    "            name=\"std\", initializer=\"zeros\"\n",
    "            )\n",
    "        self.rmse = self.add_weight(\n",
    "            name=\"rmse\", initializer=\"zeros\"\n",
    "            )\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "            )\n",
    "\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "        y_mean = tf.reduce_sum((y_true)/tf.cast(self.total_samples, tf.float32))\n",
    "        std = tf.sqrt(tf.reduce_sum(tf.square(y_true - y_mean))/tf.cast(self.total_samples, tf.float32))\n",
    "        self.std.assign_add(std)\n",
    "        rmse = tf.sqrt(tf.reduce_sum(tf.square(y_true - y_pred))/tf.cast(self.total_samples, tf.float32))\n",
    "        self.rmse.assign_add(rmse)\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        return  self.std/self.rmse\n",
    "\n",
    "\n",
    "    def reset_state(self):        \n",
    "        self.std.assign(0.)\n",
    "        self.rmse.assign(0.)\n",
    "        self.total_samples.assign(0)\n",
    "\n",
    "\n",
    "# class RPIQR(tf.keras.metrics.Metric):\n",
    "\n",
    "#     def __init__(self, name=\"rpiqr\", **kwargs):\n",
    "\n",
    "#         super().__init__(name=name, **kwargs)\n",
    "#         self.rmse = self.add_weight(\n",
    "#             name=\"rmse\", initializer=\"zeros\"\n",
    "#             )\n",
    "#         self.total_samples = self.add_weight(\n",
    "#             name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "#             )\n",
    "#         self.iqr = self.add_weight(\n",
    "#             name=\"iqr\", initializer=\"zeros\", dtype=\"float32\"\n",
    "#             )\n",
    "\n",
    "    \n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "\n",
    "#         num_samples = tf.shape(y_pred)[0]\n",
    "#         self.total_samples.assign_add(num_samples)\n",
    "#         percentiles = tfp.stats.percentile(y_true, q=[25., 75.])\n",
    "#         self.iqr.assign_add(percentiles[1]-percentiles[0])\n",
    "#         rmse = tf.sqrt(tf.reduce_sum(tf.square(y_true - y_pred))/tf.cast(self.total_samples, tf.float32))\n",
    "#         self.rmse.assign_add(rmse)\n",
    "\n",
    "\n",
    "#     def result(self):\n",
    "#         return  self.iqr/self.rmse\n",
    "\n",
    "\n",
    "#     def reset_state(self):        \n",
    "#         self.iqr.assign(0.)\n",
    "#         self.rmse.assign(0.)\n",
    "#         self.total_samples.assign(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caco3 = pd.read_csv('<path to data>')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "caco3_array = caco3.to_numpy(copy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(caco3_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL_SPLIT = int(VAL_SPLIT_FRACTION * caco3_array.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "caco3_array[:, :-1] = savgol_filter(caco3_array[:, :-1], 13, polyorder = 2, deriv=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment cell below if you want to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = Normalizer()\n",
    "# scaler.fit(caco3_array[:VAL_SPLIT])\n",
    "# caco3_array = scaler.transform(caco3_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = int(TRAIN_SPLIT_FRACTION * caco3_array.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split set to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = caco3_array[:TRAIN_SPLIT, :-1]\n",
    "# calc = caco3_array[:TRAIN_SPLIT, -1]\n",
    "train = caco3_array[:, :-1]\n",
    "calc = caco3_array[:, -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declare your callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this callback is to stop training if the model does not improve\n",
    "callback_01 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-03,\n",
    "    patience=75,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "# this callback is to save model mid-training\n",
    "callback_02 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    PATH_SAVE,\n",
    "    monitor=\"val_loss\",\n",
    "    mode = 'min',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# this callback is to reduce learning rate if the gradient reaches a plateau\n",
    "callback_03 = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    min_delta=10e-4\n",
    ")\n",
    "\n",
    "# define the function that schedules how the learning rate changes\n",
    "# this one reduces the lr by a factor of 10 every 1_500 epochs\n",
    "def scheduler(epoch, lr):\n",
    "    if not epoch%1_500:\n",
    "        lr *= tf.math.pow(10.0, -1)\n",
    "    return lr \n",
    "\n",
    "# def scheduler(epoch, lr):\n",
    "#     # LR = 0.003\n",
    "#     i = epoch//1_500\n",
    "#     lr /= 10**i\n",
    "#     return lr\n",
    "\n",
    "# then pass the scheduler function to the callback\n",
    "callback_04 = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1e-07>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-6 * tf.math.pow(10.0, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declare your regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_reg = tf.keras.regularizers.L1(l1=LAMBDA)\n",
    "L2_reg = tf.keras.regularizers.L2(l2=LAMBDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(train.shape[1]))\n",
    "# inputs = tf.keras.layers.Input(shape=(inputs.shape[1], 1))\n",
    "dense_01 = Dense(\n",
    "    units=500,\n",
    "    activation='relu',\n",
    "    # kernel_regularizer=L1_reg,\n",
    "    # activity_regularizer=L2_reg,\n",
    ")(inputs)\n",
    "# dropout_01 = Dropout(0.3)(dense_01)\n",
    "dense_02 = Dense(\n",
    "    units=200,\n",
    "    activation='relu',\n",
    "    # kernel_regularizer=L1_reg,\n",
    "    # activity_regularizer=L2_reg,\n",
    ")(dense_01)\n",
    "dense_03 = Dense(\n",
    "    units=50,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=L1_reg,\n",
    "    activity_regularizer=L2_reg,\n",
    "    )(dense_02)\n",
    "# dense_04 = Dense(\n",
    "#     units=32,\n",
    "#     activation='relu',\n",
    "#     kernel_regularizer=tf.keras.regularizers.L1(0.01),\n",
    "#     activity_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "#     )(dense_03)\n",
    "# dropout_02 = Dropout(0.3)(dense_01)\n",
    "# dense_03 = Dense(128, activation='relu')(dropout_02)\n",
    "outputs = Dense(\n",
    "    units=1,\n",
    "    # activation='exponential',\n",
    "    # kernel_constraint=non_neg(),\n",
    "    # bias_constraint=non_neg(),    \n",
    ")(dense_03)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        # clipnorm=1,\n",
    "    ),\n",
    "    loss='mean_squared_error',\n",
    "    metrics = [tfa.metrics.RSquare(), RPD()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = tf.keras.models.load_model('<model load path>', custom_objects={'RPD': RPD})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=train,\n",
    "    y= calc,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VAL_SPLIT_FRACTION,\n",
    "    callbacks=[callback_02, callback_04],  # mind the lr reducer callback!\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf35905dd43f0da56ae99027303b7872985f38af067141fd4bc8686cc13c6723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
